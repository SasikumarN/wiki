<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>Memory, Overcommit and OOM, Stack overflow</title>
<!-- 2017-04-23 Sun 22:08 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="Shi Shougang" />
<link href="../assets/bootstrap.min.css" rel="stylesheet" media="screen">
<link href="../assets/bootstrap-responsive.min.css" rel="stylesheet">
<link rel="stylesheet" type="text/css" href="../assets/stylesheet.css" />
<script src="assets/js/bootstrap.min.js"></script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">Memory, Overcommit and OOM, Stack overflow</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">Physical and virtual memory </a></li>
<li><a href="#sec-2">Kinds of memory</a></li>
<li><a href="#sec-3">Kernel memory allocation</a>
<ul>
<li><a href="#sec-3-1">Pages</a></li>
<li><a href="#sec-3-2">Buddy system</a></li>
<li><a href="#sec-3-3"><code>get_free_page</code></a></li>
<li><a href="#sec-3-4">kmalloc</a></li>
<li><a href="#sec-3-5">Priority</a></li>
<li><a href="#sec-3-6">vmalloc</a></li>
<li><a href="#sec-3-7">The slab cache</a></li>
</ul>
</li>
<li><a href="#sec-4">Overcommit and OOM</a>
<ul>
<li><a href="#sec-4-1">OOM Killer</a></li>
<li><a href="#sec-4-2">Tuning Parameters</a></li>
</ul>
</li>
<li><a href="#sec-5">Turning off overcommit</a>
<ul>
<li><a href="#sec-5-1">Some cases</a></li>
</ul>
</li>
<li><a href="#sec-6">Stack overflow</a></li>
<li><a href="#sec-7">The Linux Page Cache and pdflush:</a>
<ul>
<li><a href="#sec-7-1">writes data out</a></li>
<li><a href="#sec-7-2">pdflush tunables</a></li>
</ul>
</li>
<li><a href="#sec-8">optimize or reduce RAM size in embedded system</a>
<ul>
<li><a href="#sec-8-1">Arrays and Lookup Tables</a></li>
<li><a href="#sec-8-2">Stack and heap</a></li>
<li><a href="#sec-8-3">Global vs local variables</a></li>
<li><a href="#sec-8-4">Smaller variables</a></li>
<li><a href="#sec-8-5">Enum variable size</a></li>
<li><a href="#sec-8-6">Algorithm implementation</a></li>
</ul>
</li>
<li><a href="#sec-9">Reference</a></li>
<li><a href="#sec-10">cc</a></li>
</ul>
</div>
</div>


<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">Physical and virtual memory <sup><a id="fnr.1" name="fnr.1" class="footref" href="#fn.1">1</a></sup></h2>
<div class="outline-text-2" id="text-1">
<p>
Traditionally, one has physical memory, that is, memory that is
actually present in the machine, and virtual memory, that is, address
space. 
</p>
</div>
</div>
<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">Kinds of memory</h2>
<div class="outline-text-2" id="text-2">
<p>
Kernel and user space work with virtual addresses (also called linear
addresses) that are mapped to physical addresses by the memory
management hardware. This mapping is defined by page tables, set up by
the operating system.
</p>

<p>
DMA devices use bus addresses. On an i386 PC, bus addresses are the
same as physical addresses, but other architectures may have special
address mapping hardware to convert bus addresses to physical
addresses.
</p>

<div class="org-src-container">

<pre class="src src-sh"><span style="color: #ff7f24;">#</span><span style="color: #ff7f24;">include &lt;asm/io.h&gt;</span>

<span style="color: #eedd82;">phys_addr</span> = virt_to_phys(virt_addr);
<span style="color: #eedd82;">virt_addr</span> = phys_to_virt(phys_addr);
 <span style="color: #eedd82;">bus_addr</span> = virt_to_bus(virt_addr);
<span style="color: #eedd82;">virt_addr</span> = bus_to_virt(bus_addr);
</pre>
</div>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">Kernel memory allocation</h2>
<div class="outline-text-2" id="text-3">
</div><div id="outline-container-sec-3-1" class="outline-3">
<h3 id="sec-3-1">Pages</h3>
<div class="outline-text-3" id="text-3-1">
<p>
The basic unit of memory is the <code>page</code>. It is architecture-dependent,
but typically <code>PAGE_SIZE = 4096</code>.
</p>

<p>
Usually, the page size is determined by the hardware: the relation
between virtual addresses and physical addresses is given by page
tables, and when a virtual address is referenced that does not (yet)
correspond to a physical address, a <i>page fault</i> occurs, and the
operating system can take appropriate action
</p>
</div>
</div>

<div id="outline-container-sec-3-2" class="outline-3">
<h3 id="sec-3-2">Buddy system</h3>
<div class="outline-text-3" id="text-3-2">
<p>
The kernel uses a buddy system with power-of-two sizes. For order 0,
1, 2, &#x2026;, 9 it has lists of areas containing 2<sup>order</sup> pages. If a
small area is needed and only a larger area is available, the larger
area is split into two halves (buddies), possibly repeatedly. The
number of free areas of each order can be seen in <code>/proc/buddyinfo</code>.
When an area is freed, it is checked whether its buddy is free as
well, and if so they are merged. Read the code in <code>mm/page_alloc.c</code>.
</p>
</div>
</div>

<div id="outline-container-sec-3-3" class="outline-3">
<h3 id="sec-3-3"><code>get_free_page</code></h3>
<div class="outline-text-3" id="text-3-3">
<p>
The routine <code>__get_free_page()</code> will give us a page. The routine
<code>__get_free_pages()</code> will give a number of consecutive pages. (A power
of two, from 1 to 512 or so. The above buddy system is used.)
</p>
</div>
</div>
<div id="outline-container-sec-3-4" class="outline-3">
<h3 id="sec-3-4">kmalloc</h3>
<div class="outline-text-3" id="text-3-4">
<p>
The routine kmalloc() is good for an area of unknown, arbitrary,
smallish length, in the range 32-131072 (more precisely: 1/128 of a
page up to 32 pages), preferably below 4096. For the sizes, see
<code>&lt;linux/kmalloc_sizes.h&gt;</code>. Because of fragmentation, it will be
difficult to get large consecutive areas from <code>kmalloc()</code>. These days
<code>kmalloc()</code> returns memory from one of a series of slab caches (see
below) with names like "size-32", &#x2026;, "size-131072".
</p>
</div>
</div>

<div id="outline-container-sec-3-5" class="outline-3">
<h3 id="sec-3-5">Priority</h3>
<div class="outline-text-3" id="text-3-5">
<p>
There is a bit specifying whether we would like a hot or a cold page
(that is, a page likely to be in the CPU cache, or a page not likely
to be there). If the page will be used by the CPU, a hot page will be
faster. If the page will be used for device DMA the CPU cache would be
invalidated anyway, and a cold page does not waste precious cache
contents.
</p>

<div class="org-src-container">

<pre class="src src-c"><span style="color: #ff7f24;">//</span><span style="color: #ff7f24;">linux/gfp.h</span>
<span style="color: #ff7f24;">/* </span><span style="color: #ff7f24;">Zone modifiers in GFP_ZONEMASK (see linux/mmzone.h - low four bits) </span><span style="color: #ff7f24;">*/</span>
<span style="color: #b0c4de;">#define</span> <span style="color: #eedd82;">__GFP_DMA</span>       0x01

<span style="color: #ff7f24;">/* </span><span style="color: #ff7f24;">Action modifiers - doesn't change the zoning </span><span style="color: #ff7f24;">*/</span>
<span style="color: #b0c4de;">#define</span> <span style="color: #eedd82;">__GFP_WAIT</span>      0x10    <span style="color: #ff7f24;">/* </span><span style="color: #ff7f24;">Can wait and reschedule? </span><span style="color: #ff7f24;">*/</span>
<span style="color: #b0c4de;">#define</span> <span style="color: #eedd82;">__GFP_HIGH</span>      0x20    <span style="color: #ff7f24;">/* </span><span style="color: #ff7f24;">Should access emergency pools? </span><span style="color: #ff7f24;">*/</span>
<span style="color: #b0c4de;">#define</span> <span style="color: #eedd82;">__GFP_IO</span>        0x40    <span style="color: #ff7f24;">/* </span><span style="color: #ff7f24;">Can start low memory physical IO? </span><span style="color: #ff7f24;">*/</span>
<span style="color: #b0c4de;">#define</span> <span style="color: #eedd82;">__GFP_FS</span>        0x100   <span style="color: #ff7f24;">/* </span><span style="color: #ff7f24;">Can call down to low-level FS? </span><span style="color: #ff7f24;">*/</span>
<span style="color: #b0c4de;">#define</span> <span style="color: #eedd82;">__GFP_COLD</span>      0x200   <span style="color: #ff7f24;">/* </span><span style="color: #ff7f24;">Cache-cold page required </span><span style="color: #ff7f24;">*/</span>

<span style="color: #b0c4de;">#define</span> <span style="color: #eedd82;">GFP_NOIO</span>        (__GFP_WAIT)
<span style="color: #b0c4de;">#define</span> <span style="color: #eedd82;">GFP_NOFS</span>        (__GFP_WAIT | __GFP_IO )
<span style="color: #b0c4de;">#define</span> <span style="color: #eedd82;">GFP_ATOMIC</span>      (__GFP_HIGH)
<span style="color: #b0c4de;">#define</span> <span style="color: #eedd82;">GFP_USER</span>        (__GFP_WAIT | __GFP_IO | __GFP_FS)
<span style="color: #b0c4de;">#define</span> <span style="color: #eedd82;">GFP_KERNEL</span>      (__GFP_WAIT | __GFP_IO | __GFP_FS)
</pre>
</div>

<p>
Uses:
</p>

<ul class="org-ul">
<li><code>GFP_KERNEL</code> is the default flag. Sleeping is allowed.
</li>
<li><code>GFP_ATOMIC</code> is used in interrupt handlers. Never sleeps.
</li>
<li><code>GFP_USER</code> for user mode allocations. Low priority, and may sleep. (Today equal to GFP<sub>KERNEL</sub>.)
</li>
<li><code>GFP_NOIO</code> must not call down to drivers (since it is used from drivers).
</li>
<li><code>GFP_NOFS</code> must not call down to filesystems (since it is used from
filesystems &#x2013; see, e.g., dcache.c: <code>shrink_dcache_memory</code> and
inode.c: <code>shrink_icache_memory</code>).
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-3-6" class="outline-3">
<h3 id="sec-3-6">vmalloc</h3>
<div class="outline-text-3" id="text-3-6">
<p>
The routine <code>vmalloc()</code> has a similar purpose, but has a better chance
of being able to return larger consecutive areas, and is more
expensive. It uses page table manipulation to create an area of memory
that is consecutive in virtual memory, but not necessarily in physical
memory. Device I/O to such an area is a bad idea. It uses the above
calls with <code>GFP_KERNEL</code> to get its memory, so cannot be used in
interrupt context.
</p>
</div>
</div>
<div id="outline-container-sec-3-7" class="outline-3">
<h3 id="sec-3-7">The slab cache</h3>
<div class="outline-text-3" id="text-3-7">
<p>
The routine <code>kmalloc</code> is general purpose, and may waste up to 50%
space. The pool is created using <code>kmem_cache_create()</code>, and allocation
is by <code>kmem_cache_alloc()</code>.
</p>

<p>
Statistics is found in <code>/proc/slabinfo</code>.
</p>
</div>
<ul class="org-ul"><li><a id="sec-3-7-1" name="sec-3-7-1"></a>/proc/slabinfo and slaptop<br  /><div class="outline-text-4" id="text-3-7-1">
<p>
/proc/slabinfo gives information about memory usage on the slab level.
Linux kernels uses slab pools to manage memory above the page level.
Commonly used objects have their own slab pools. Instead of parsing
the highly verbose /proc/slabinfo file manually, the /usr/bin/slabtop
program displays kernel slab cache information in real time. 
</p>

<div class="org-src-container">

<pre class="src src-sh">$ sudo slabtop
 Active / Total Objects (% used)    : 2043086 / 2077868 (98.3%)
 Active / Total Slabs (% used)      : 66387 / 66387 (100.0%)
 Active / Total Caches (% used)     : 73 / 102 (71.6%)
 Active / Total Size (% used)       : 701264.41K / 707117.73K (99.2%)
 Minimum / Average / Maximum Object : 0.01K / 0.34K / 15.75K

  OBJS ACTIVE  USE OBJ SIZE  SLABS OBJ/SLAB CACHE SIZE NAME                   
580209 579912  99%    0.19K  27629       21    110516K dentry
491439 472694  96%    0.10K  12601       39     50404K buffer_head
468138 468023  99%    0.96K  14186       33    453952K ext4_inode_cache
151470 151470 100%    0.04K   1485      102      5940K ext4_extent_status
 75520  71867  95%    0.06K   1180       64      4720K kmalloc-64
 44961  40943  91%    0.19K   2141       21      8564K kmalloc-192
 37400  37400 100%    0.12K   1100       34      4400K fsnotify_event
 35868  34052  94%    0.55K   1281       28     20496K radix_tree_node
 34164  34164 100%    0.11K    949       36      3796K sysfs_dir_cache
 18480  16311  88%    0.07K    330       56      1320K anon_vma
</pre>
</div>
<p>
Important parameters in <code>/proc/slabinfo</code> are as below :
</p>

<ul class="org-ul">
<li>OBJS — The total number of objects (memory blocks), including those
in use (allocated), and some spares not in use.
</li>
<li>ACTIVE — The number of objects (memory blocks) that are in use
(allocated).
</li>
<li>USE — Percentage of total objects that are active. ((ACTIVE/OBJS)(100))
</li>
<li>OBJ SIZE — The size of the objects.
</li>
<li>SLABS — The total number of slabs.
</li>
<li>OBJ/SLAB — The number of objects that fit into a slab.
</li>
<li>CACHE SIZE — The cache size of the slab.
</li>
<li>NAME — The name of the slab.
</li>
</ul>
</div>
</li></ul>
</div>
</div>
<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4">Overcommit and OOM</h2>
<div class="outline-text-2" id="text-4">
<p>
Linux on the other hand is seriously broken. It will by default answer
"yes" to most requests for memory, in the hope that programs ask for
more than they actually need. If the hope is fulfilled Linux can run
more programs in the same memory, or can run a program that requires
more virtual memory than is available. And if not then very bad things
happen.
</p>

<p>
What happens is that the <b>OOM killer</b> (OOM = out-of-memory) is invoked,
and it will select some process and kill it. One holds long
discussions about the choice of the victim. Maybe not a root process,
maybe not a process doing raw I/O, maybe not a process that has
already spent weeks doing some computation. 
</p>

<p>
To facilitate this, the kernel maintains <code>oom_score</code> for each of the
processes. You can see the <code>oom_score</code> of each of the processes in the
<code>/proc</code> filesystem under the pid directory
</p>

<p>
<code># cat /proc/10292/oom_score</code>
</p>

<p>
Higher the value of <code>oom_score</code> of any process the higher is its
likelihood of getting killed by the OOM Killer in an out-of-memory
situation.
</p>

<p>
More:
</p>
<ul class="org-ul">
<li><a href="https://lwn.net/Articles/317814/">Taming the OOM killer</a>
</li>
</ul>
</div>
<div id="outline-container-sec-4-1" class="outline-3">
<h3 id="sec-4-1">OOM Killer</h3>
<div class="outline-text-3" id="text-4-1">
<p>
The functions, code excerpts and comments discussed below here are
from <code>mm/oom_kill.c</code> unless otherwise noted.
</p>

<p>
It is the job of the linux 'oom killer' to sacrifice one or more
processes in order to free up memory for the system when all else
fails. It will also kill any process sharing the same <code>mm_struct</code> as the
selected process, for obvious reasons. Any particular process leader
may be immunized against the oom killer if the value of its
<code>/proc/&lt;pid&gt;/oomadj</code> is set to the constant <code>OOM_DISABLE</code> (currently
defined as -17).
</p>

<p>
The function which does the actual scoring of a process in the effort
to find the best candidate for elimination is called badness(), which
results from the following call chain:
</p>

<p>
<code>_alloc_pages -&gt; out_of_memory() -&gt; select_bad_process() -&gt; badness()</code>
</p>
</div>
</div>

<div id="outline-container-sec-4-2" class="outline-3">
<h3 id="sec-4-2">Tuning Parameters</h3>
<div class="outline-text-3" id="text-4-2">
<p>
For more info on this: 
</p>
<ul class="org-ul">
<li><a href="https://www.kernel.org/doc/Documentation/sysctl/vm.txt">kernel doc</a>
</li>
<li><a href="http://russ.garrett.co.uk/2009/01/01/linux-kernel-tuning/">kernel tuning</a>
</li>
</ul>
</div>

<ul class="org-ul"><li><a id="sec-4-2-1" name="sec-4-2-1"></a><code>overcommit_ratio</code><br  /><div class="outline-text-4" id="text-4-2-1">
<p>
Which happened to be 50. And the machine just happened to have about
5GB of RAM. Well look there, 5×50 is 250GB
</p>

<p>
If a process tries to malloc() more memory than available it will get
an error right away. This mode is set by changing the sysctl value
vm.overcommit<sub>memory</sub> to 2.
</p>
</div>
</li>
<li><a id="sec-4-2-2" name="sec-4-2-2"></a><code>vm.overcommit_ratio</code><br  /></li>
<li><a id="sec-4-2-3" name="sec-4-2-3"></a><code>vm.min_free_kbytes = 65536</code><br  /><div class="outline-text-4" id="text-4-2-3">
<p>
This tells the kernel to try and keep 64MB of RAM free at all times. It’s useful in two main cases:
</p>

<ul class="org-ul">
<li>Swap-less machines, where you don’t want incoming network traffic to
overwhelm the kernel and force an OOM before it has time to flush
any buffers.
</li>

<li>x86 machines, for the same reason: the x86 architecture only allows
DMA transfers below approximately 900MB of RAM. So you can end up
with the bizarre situation of an OOM error with tons of RAM free.
</li>
</ul>
</div>
</li>

<li><a id="sec-4-2-4" name="sec-4-2-4"></a><code>vm.min_free_kbytes</code> &lt; lowmem<br  /><div class="outline-text-4" id="text-4-2-4">
<p>
vm.min<sub>free</sub><sub>kbytes</sub> 设定值高于LowTotal 值，系统认为没有足够的lowmem，而触发OOM Killer，将进程强行杀掉。
</p>

<p>
系统中内存分为lowmem和highmem，其中lowmem为寻址内存，当lowmem耗尽时，系统会触动OOM Killer将多余进程杀掉来释放内
</p>
</div>
</li>

<li><a id="sec-4-2-5" name="sec-4-2-5"></a><code>vm.swappiness = 0</code><br  /><div class="outline-text-4" id="text-4-2-5">
<p>
It’s said that altering swappiness can help you when you’re running
under high memory pressure with software that tries to do its own
memory management (i.e. MySQL). We’ve had limited success with this
and I’d much prefer to use software which doesn’t pretend to know more
about your hardware than the OS (i.e. PostgreSQL). Not that I’m
bitter.
</p>
</div>
</li>

<li><a id="sec-4-2-6" name="sec-4-2-6"></a><code>vm.overcommit_memory=1</code><br  /><div class="outline-text-4" id="text-4-2-6">
<p>
The overcommit<sub>memory</sub> sysctl isn’t something you’ll usually have to
change if your software isn’t insane, but our netboot setup uses it so
I thought I’d mention it. From the documentation:
</p>

<ol class="org-ol">
<li>- Heuristic overcommit handling. Obvious overcommits of address
space are refused. Used for a typical system. It ensures a
seriously wild allocation fails while allowing overcommit to reduce
swap usage. root is allowed to allocate slighly more memory in this
mode. This is the default.
</li>
<li>- Always overcommit. Appropriate for some scientific applications.
</li>
<li>- Don’t overcommit. The total address space commit for the system
is not permitted to exceed swap + a configurable percentage
(default is 50) of physical RAM. Depending on the percentage you
use, in most situations this means a process will not be killed
while accessing pages but will receive errors on memory allocation
as appropriate.
</li>
</ol>
</div>
</li></ul>
</div>
</div>

<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5">Turning off overcommit</h2>
<div class="outline-text-2" id="text-5">
<p>
Since 2.5.30 the values are: 
</p>
<ul class="org-ul">
<li>0 (default): as before: guess about how much overcommitment is reasonable, 
</li>
<li>1: never refuse any <code>malloc()</code>, 
</li>
<li>2: be precise about the overcommit - never commit a virtual address
space larger than swap space plus a fraction <code>overcommit_ratio</code> of
the physical memory. 
</li>
</ul>

<p>
Here <code>/proc/sys/vm/overcommit_ratio</code> (by default 50) is
another user-settable parameter. It is possible to set
<code>overcommit_ratio</code> to values larger than 100. 
</p>

<p>
One can view the currently committed amount of memory in
<code>/proc/meminfo</code>, in the field <code>Committed_AS</code>.
</p>
</div>
<div id="outline-container-sec-5-1" class="outline-3">
<h3 id="sec-5-1">Some cases</h3>
<div class="outline-text-3" id="text-5-1">
</div><ul class="org-ul"><li><a id="sec-5-1-1" name="sec-5-1-1"></a>OOM killer crashes<sup><a id="fnr.2" name="fnr.2" class="footref" href="#fn.2">2</a></sup><br  /><div class="outline-text-4" id="text-5-1-1">
<p>
To fix OOM crash the behavior of the kernel has to be changed, so it
will no longer overcommit the memory for application requests. 
</p>

<div class="org-src-container">

<pre class="src src-sh">vm.overcommit_memory = 2
vm.overcommit_ratio = 80
</pre>
</div>
</div>
</li></ul>
</div>
</div>

<div id="outline-container-sec-6" class="outline-2">
<h2 id="sec-6">Stack overflow</h2>
<div class="outline-text-2" id="text-6">
<p>
Processes use memory on the stack and on the heap. Heap memory is
provided by <code>malloc()</code> or the underlying mechanisms. The stack grows
until it no longer can, and the process is hit by a SIGSEGV signal, a
segmentation violation (because of the access of a location just
beyond the end of the stack), and is killed. 
</p>

<p>
A simple demo that catches SIGSEGV:
</p>

<div class="org-src-container">

<pre class="src src-c"><span style="color: #b0c4de;">#include</span> <span style="color: #ffa07a;">&lt;stdio.h&gt;</span>
<span style="color: #b0c4de;">#include</span> <span style="color: #ffa07a;">&lt;stdlib.h&gt;</span>
<span style="color: #b0c4de;">#include</span> <span style="color: #ffa07a;">&lt;signal.h&gt;</span>

<span style="color: #98fb98;">void</span> <span style="color: #87cefa;">segfault</span>(<span style="color: #98fb98;">int</span> <span style="color: #eedd82;">dummy</span>) {
        printf(<span style="color: #ffa07a;">"Help!\n"</span>);
        exit(1);
}

<span style="color: #98fb98;">int</span> <span style="color: #87cefa;">main</span>() {
        <span style="color: #98fb98;">int</span> *<span style="color: #eedd82;">p</span> = 0;

        signal(SIGSEGV, segfault);
        *p = 17;
        <span style="color: #00ffff;">return</span> 0;
}
</pre>
</div>
<p>
Without the exit() here, this demo will loop because the illegal assignment is restarted.
This simple demo fails to catch stack overflow, because there is no stack space for a call frame for the segfault() interrupt handler. If it is desired to catch stack overflow one first must set up an alternative stack. As follows:
</p>

<div class="org-src-container">

<pre class="src src-c">...
<span style="color: #98fb98;">int</span> main() {
        <span style="color: #98fb98;">char</span> <span style="color: #eedd82;">myaltstack</span>[SIGSTKSZ];
        <span style="color: #00ffff;">struct</span> <span style="color: #98fb98;">sigaction</span> <span style="color: #eedd82;">act</span>;
        <span style="color: #98fb98;">stack_t</span> <span style="color: #eedd82;">ss</span>;

        ss.ss_sp = myaltstack;
        ss.ss_size = <span style="color: #00ffff;">sizeof</span>(myaltstack);
        ss.ss_flags = 0;
        <span style="color: #00ffff;">if</span> (sigaltstack(&amp;ss, <span style="color: #7fffd4;">NULL</span>))
                errexit(<span style="color: #ffa07a;">"sigaltstack failed"</span>);

        act.sa_handler = segfault;
        act.sa_flags = SA_ONSTACK;
        <span style="color: #00ffff;">if</span> (sigaction(SIGSEGV, &amp;act, <span style="color: #7fffd4;">NULL</span>))
                errexit(<span style="color: #ffa07a;">"sigaction failed"</span>);
...
</pre>
</div>
</div>
</div>

<div id="outline-container-sec-7" class="outline-2">
<h2 id="sec-7">The Linux Page Cache and pdflush:<sup><a id="fnr.3" name="fnr.3" class="footref" href="#fn.3">3</a></sup></h2>
<div class="outline-text-2" id="text-7">
</div><div id="outline-container-sec-7-1" class="outline-3">
<h3 id="sec-7-1">writes data out</h3>
<div class="outline-text-3" id="text-7-1">
<p>
Linux usually writes data out of the page cache using a process called
pdflush. At any moment, between 2 and 8 pdflush threads are running on
the system. You can monitor how many are active by looking at
<code>/proc/sys/vm/nr_pdflush_threads</code>. Whenever all existing pdflush threads
are busy for at least one second, an additional pdflush daemon is
spawned. The new ones try to write back data to device queues that are
not congested, aiming to have each device that's active get its own
thread flushing data to that device. Each time a second has passed
without any pdflush activity, one of the threads is removed. There are
tunables for adjusting the minimum and maximum number of pdflush
processes, but it's very rare they need to be adjusted.
</p>
</div>
</div>
<div id="outline-container-sec-7-2" class="outline-3">
<h3 id="sec-7-2">pdflush tunables</h3>
<div class="outline-text-3" id="text-7-2">
<p>
Exactly what each pdflush thread does is controlled by a series of
parameters in /proc/sys/vm:
</p>
</div>

<ul class="org-ul"><li><a id="sec-7-2-1" name="sec-7-2-1"></a><code>/proc/sys/vm/dirty_writeback_centisecs</code><br  /><div class="outline-text-4" id="text-7-2-1">
<p>
(default 500): In hundredths of a second, this is how often pdflush
wakes up to write data to disk. The default wakes up the two (or more)
active threads every five seconds.
</p>

<p>
Because of all this, it's unlikely you'll gain much benefit from
lowering the writeback time; the thread spawning code assures that
they will automatically run themselves as often as is practical to try
and meet the other requirements.
</p>
</div>
</li>

<li><a id="sec-7-2-2" name="sec-7-2-2"></a><code>/proc/sys/vm/dirty_expire_centiseconds</code><br  /><div class="outline-text-4" id="text-7-2-2">
<p>
The first thing pdflush works on is writing pages that have been dirty
for longer than it deems acceptable.
</p>

<p>
(default 3000): In hundredths of a second, how long data can be in the
page cache before it's considered expired and must be written at the
next opportunity. Note that this default is very long: a full 30
seconds. That means that under normal circumstances, unless you write
enough to trigger the other pdflush method, Linux won't actually
commit anything you write until 30 seconds later.
</p>
</div>
</li>
<li><a id="sec-7-2-3" name="sec-7-2-3"></a><code>/proc/sys/vm/dirty_background_ratio</code><br  /><div class="outline-text-4" id="text-7-2-3">
<p>
(default 10): Maximum percentage of active that can be filled with
dirty pages before pdflush begins to write them
</p>

<p>
Note that some kernel versions may internally put a lower bound on
this value at 5%.
</p>

<p>
Most of the documentation you'll find about this parameter suggests
it's in terms of total memory, but a look at the source code shows
this isn't true. In terms of the meminfo output, the code actually
looks at <code>MemFree + Cached - Mapped</code>-
</p>
</div>
</li>
<li><a id="sec-7-2-4" name="sec-7-2-4"></a>Summary: when does pdflush write?<br  /><div class="outline-text-4" id="text-7-2-4">
<p>
In the default configuration, then, data written to disk will sit in
memory until either a) they're more than 30 seconds old, or b) the
dirty pages have consumed more than 10% of the active, working memory.
If you are writing heavily, once you reach the <code>dirty_background_ratio</code>
driven figure worth of dirty memory, you may find that all your writes
are driven by that limit.
</p>
</div>
</li>
<li><a id="sec-7-2-5" name="sec-7-2-5"></a><code>/proc/sys/vm/dirty_ratio</code><br  /><div class="outline-text-4" id="text-7-2-5">
<p>
<code>/proc/sys/vm/dirty_ratio</code> (default 40): Maximum percentage of total
memory that can be filled with dirty pages before processes are forced
to write dirty buffers themselves during their time slice instead of
being allowed to do more writes.
</p>
</div>
</li></ul>
</div>
</div>

<div id="outline-container-sec-8" class="outline-2">
<h2 id="sec-8">optimize or reduce RAM size in embedded system<sup><a id="fnr.4" name="fnr.4" class="footref" href="#fn.4">4</a></sup></h2>
<div class="outline-text-2" id="text-8">
</div><div id="outline-container-sec-8-1" class="outline-3">
<h3 id="sec-8-1">Arrays and Lookup Tables</h3>
<div class="outline-text-3" id="text-8-1">
<p>
Check for look-up tables that haven't used the <code>const</code> declaration
properly, which puts them in RAM instead of ROM.
</p>

<div class="org-src-container">

<pre class="src src-c"><span style="color: #00ffff;">const</span> <span style="color: #98fb98;">my_struct_t</span> * <span style="color: #eedd82;">param_lookup</span>[] = {...};  <span style="color: #ff7f24;">// </span><span style="color: #ff7f24;">Table is in RAM!</span>
<span style="color: #98fb98;">my_struct_t</span> * <span style="color: #00ffff;">const</span> <span style="color: #eedd82;">param_lookup</span>[] = {...};  <span style="color: #ff7f24;">// </span><span style="color: #ff7f24;">In ROM</span>
<span style="color: #00ffff;">const</span> <span style="color: #98fb98;">char</span> * <span style="color: #00ffff;">const</span> <span style="color: #eedd82;">strings</span>[] = {...};    <span style="color: #ff7f24;">// </span><span style="color: #ff7f24;">Two const may be needed; also in ROM</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-sec-8-2" class="outline-3">
<h3 id="sec-8-2">Stack and heap</h3>
<div class="outline-text-3" id="text-8-2">
<p>
Perhaps your linker config reserves large amounts of RAM for heap and
stack, larger than necessary for your application.
</p>

<p>
If you don't use heap, you can possibly eliminate that.
</p>

<p>
If you measure your stack usage and it's well under the allocation,
you may be able to reduce the allocation. For ARM processors, there
can be several stacks, for several of the operating modes, and you may
find that the stacks allocated for the exception or interrupt
operating modes are larger than needed.
</p>
</div>
</div>
<div id="outline-container-sec-8-3" class="outline-3">
<h3 id="sec-8-3">Global vs local variables</h3>
<div class="outline-text-3" id="text-8-3">
<p>
Check for unnecessary use of static or global variables, where a local
variable (on the stack) can be used instead.
</p>
</div>
</div>
<div id="outline-container-sec-8-4" class="outline-3">
<h3 id="sec-8-4">Smaller variables</h3>
<div class="outline-text-3" id="text-8-4">
<p>
Variables that can be smaller, e.g. <code>int16_t</code> (<code>short</code>) or <code>int8_t</code> (<code>char</code>)
instead of <code>int32_t</code> (<code>int</code>).
</p>
</div>
</div>
<div id="outline-container-sec-8-5" class="outline-3">
<h3 id="sec-8-5">Enum variable size</h3>
<div class="outline-text-3" id="text-8-5">
<p>
<code>enum</code> variable size may be bigger than necessary. I can't remember what
ARM compilers typically do, but some compilers I've used in the past
by default made <code>enum</code> variables 2 bytes even though the <code>enum</code> definition
really only required 1 byte to store its range. Check compiler
settings.
</p>
</div>
</div>
<div id="outline-container-sec-8-6" class="outline-3">
<h3 id="sec-8-6">Algorithm implementation</h3>
<div class="outline-text-3" id="text-8-6">
<p>
Rework your algorithms. Some algorithms have have a range of possible
implementations with a speed/memory trade-off.
</p>
</div>
</div>
</div>

<div id="outline-container-sec-9" class="outline-2">
<h2 id="sec-9">Reference</h2>
<div class="outline-text-2" id="text-9">
<ul class="org-ul">
<li>Understanding the Linux Virtual Memory Manager By Mel Gorman
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-10" class="outline-2">
<h2 id="sec-10">cc</h2>
<div class="outline-text-2" id="text-10">
<div class="org-src-container">

<pre class="src src-sh"></pre>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" name="fn.1" class="footnum" href="#fnr.1">1</a></sup> <p class="footpara">
<a href="http://www.win.tue.nl/~aeb/linux/lk/lk-9.html">http://www.win.tue.nl/~aeb/linux/lk/lk-9.html</a>
</p></div>

<div class="footdef"><sup><a id="fn.2" name="fn.2" class="footnum" href="#fnr.2">2</a></sup> <p class="footpara">
<a href="https://www.hskupin.info/2010/06/17/how-to-fix-the-oom-killer-crashe-under-linux/">https://www.hskupin.info/2010/06/17/how-to-fix-the-oom-killer-crashe-under-linux/</a>
</p></div>

<div class="footdef"><sup><a id="fn.3" name="fn.3" class="footnum" href="#fnr.3">3</a></sup> <p class="footpara">
<a href="http://www.westnet.com/~gsmith/content/linux-pdflush.htm">http://www.westnet.com/~gsmith/content/linux-pdflush.htm</a>
</p></div>

<div class="footdef"><sup><a id="fn.4" name="fn.4" class="footnum" href="#fnr.4">4</a></sup> <p class="footpara">
<a href="http://stackoverflow.com/questions/5685454/how-to-optimize-or-reduce-ram-size-in-embedded-system-software">http://stackoverflow.com/questions/5685454/how-to-optimize-or-reduce-ram-size-in-embedded-system-software</a>
</p></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Shi Shougang</p>
<p class="date">Created: 2017-04-23 Sun 22:08</p>
<p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.3.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
